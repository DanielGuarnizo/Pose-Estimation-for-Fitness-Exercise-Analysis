{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=orange> Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "landmarks = ['class']\n",
    "for val in range(1, 33+1): # 33 landmarks in total\n",
    "    landmarks += ['x{}'.format(val), 'y{}'.format(val), 'z{}'.format(val), 'v{}'.format(val)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=orange> - Create CVS files"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Import Dependencies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "import cv2\n",
    "import numpy\n",
    "\n",
    "import csv\n",
    "import os\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import time"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Main Code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_line_CSV_file(path):\n",
    "\n",
    "    landmarks = ['class']\n",
    "    for val in range(1, 33+1): # 33 landmarks in total\n",
    "        landmarks += ['x{}'.format(val), 'y{}'.format(val), 'z{}'.format(val), 'v{}'.format(val)]\n",
    "\n",
    "    with open(path, mode='w', newline='') as f:\n",
    "        csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting = csv.QUOTE_MINIMAL)\n",
    "        csv_writer.writerow(landmarks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_landmark(results, action, path):\n",
    "    try:\n",
    "        keypoints = np.array([[res.x, res.y, res.z, res.visibility] for res in results.pose_landmarks.landmark]).flatten().tolist()\n",
    "        keypoints.insert(0,action)\n",
    "\n",
    "        with open(path, mode='a', newline='') as f:\n",
    "            csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "            csv_writer.writerow(keypoints)\n",
    "    except Exception as e:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is a function to automatically label videos.\n",
    "\n",
    "\n",
    "While the video indicated by the path is reproducing we press on the keyboard the keys (the mapping is stored in the variable \"labels\") corresponding to the poses we see in the video. These poses are our classes that will automatically be stored in the CSV file with the associated set of landmarks extracted when we press the key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labeling_video(path_video, labels, path_CSV):\n",
    "    mp_drawing = mp.solutions.drawing_utils\n",
    "    mp_pose = mp.solutions.pose\n",
    "\n",
    "    cap = cv2.VideoCapture(path_video)\n",
    "    with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "        while cap.isOpened():\n",
    "            ret, image = cap.read()\n",
    "\n",
    "            # Recolor Feed\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            image.flags.writeable = False\n",
    "\n",
    "            # Make Detections\n",
    "            results = pose.process(image)\n",
    "\n",
    "            # Recolor image back to BGR for rendering\n",
    "            image.flags.writeable = True\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "            mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                                    mp_drawing.DrawingSpec(color=(245, 117, 66), thickness=2, circle_radius=4),\n",
    "                                    mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2))\n",
    "        \n",
    "            k = cv2.waitKey(1)\n",
    "            for label,asci in labels.items():\n",
    "                if k == asci:\n",
    "                    export_landmark(results, label, path_CSV)\n",
    "\n",
    "            cv2.imshow('Raw Webcam Feed', image)\n",
    "\n",
    "            key = cv2.waitKey(1)\n",
    "            if key == ord('q'):\n",
    "                break\n",
    "\n",
    "        cap.release()\n",
    "        cv2.waitKey(1)\n",
    "        cv2.destroyAllWindows()\n",
    "        cv2.waitKey(1)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=green> - ***Deadlift***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_CSV = 'CSV_files/coords_DL_C_new.csv'\n",
    "path_videos = ['Videos/CorrectDeadlift_45f.mp4','Videos/RollingDeadlift_45f.mp4','Videos/BackDeadlift_45f.mp4']\n",
    "labels = {\"up\":117, \"down\":100, \"down_low\":108, \"down_roll\":114, \"up_back\":98, \"up_roll\": 103}\n",
    "    #    \"up\": u ,  \"down\": d , \"down_low\":l,   \"down_roll\":r,   \"up_back\":b,  \"up_roll\":g\n",
    "\n",
    "first_line_CSV_file(path_CSV) # this line is only execute once\n",
    "\n",
    "for path_video in path_videos:\n",
    "    labeling_video(path_video, labels,path_CSV)\n",
    "    time.sleep(6)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=green> - ***Squat***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_CSV = 'CSV_files/coords_SQ_C_new.csv'\n",
    "path_videos = ['Videos/CorrectSquat_45f.mp4','Videos/ForwardSquat_45f.mp4','Videos/DeepSquat.mp4']\n",
    "labels = {\"up\":117, \"down\":100, \"down_deep\":108, \"down_forward\":102}\n",
    "    #    \"up\": u ,  \"down\": d , \"down_deep\":l,   \"down_forward\":f\n",
    "\n",
    "first_line_CSV_file(path_CSV) # this line is only executed once\n",
    "\n",
    "for path_video in path_videos:\n",
    "    labeling_video(path_video, labels,path_CSV)\n",
    "    time.sleep(6)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=green> - ***Bench Press***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "landmarks = ['class']\n",
    "for val in range(1, 22+1): # 22 landmarks in total to avoid hip influence in the model \n",
    "    landmarks += ['x{}'.format(val), 'y{}'.format(val), 'z{}'.format(val), 'v{}'.format(val)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_CSV = 'CSV_files/coords_BP_C_new.csv'\n",
    "path_videos = ['Videos/CorrectBench_45f.mp4', 'Videos/TietBench_45f.mp4','Videos/RollBench_45f.mp4']\n",
    "labels = {\"up\":117, \"down\":100, \"down_close\":108, \"up_close\":99, \"up_roll\":114}\n",
    "    #     \"up\": u , \"down\": d , \"down_close\":l,   \"up_close\":c , 'up_roll': r\n",
    "\n",
    "first_line_CSV_file(path_CSV) # this line is only executed once\n",
    "\n",
    "for path_video in path_videos:\n",
    "    labeling_video(path_video, labels, path_CSV)\n",
    "    time.sleep(6)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=orange> - Train Models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - import Dependencies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier \n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "import pickle"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Main Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Create_sample_label_dataset(path_CSV):\n",
    "    # Create DataFrame\n",
    "    df = pd.read_csv(path_CSV)\n",
    "\n",
    "    # sample and label datasets \n",
    "    X = df.drop('class', axis=1) # features\n",
    "    y=df['class'] #target value\n",
    "\n",
    "    # divide traning and test dataset\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "    return (X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelines = {\n",
    "    'lr': make_pipeline(StandardScaler(), LogisticRegression()),\n",
    "    'rc': make_pipeline(StandardScaler(), RidgeClassifier()),\n",
    "    'rf': make_pipeline(StandardScaler(), RandomForestClassifier()),\n",
    "    'gb': make_pipeline(StandardScaler(), GradientBoostingClassifier()),\n",
    "}\n",
    "\n",
    "def Train_Model(X_train, y_train):\n",
    "    fitted_models = {}\n",
    "    for algo, pipeline in pipelines.items():\n",
    "        model = pipeline.fit(X_train, y_train)\n",
    "        fitted_models[algo] = model\n",
    "    \n",
    "    return fitted_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST ACCURACY MODELS \n",
    "def Test_Accuracy(fitted_models, X_test, y_test):\n",
    "    for algo, model in fitted_models.items():\n",
    "        yhat = model.predict(X_test)\n",
    "        print(algo, accuracy_score(y_test.values, yhat),\n",
    "            precision_score(y_test.values, yhat, average='macro'),\n",
    "            recall_score(y_test.values, yhat, average='macro'))\n",
    "            # the precision_score and recall_score functions are called with the average parameter\n",
    "            # set to 'macro' instead of 'binary'. This means that the precision and recall scores \n",
    "            # will be computed for each of the six classes and then averaged to give a single score \n",
    "            # for each metric"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=green> - ***Train Deadlift***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_CSV = '/Users/danielguarnizo/Desktop/ProjectCV/CSV_files/coords_DL_C.csv'\n",
    "X_train, X_test, y_train, y_test = Create_sample_label_dataset(path_CSV)\n",
    "fitted_models = Train_Model(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr 0.9986559139784946 0.9990310077519379 0.9985875706214689\n",
      "rc 0.9986559139784946 0.9990310077519379 0.9985875706214689\n",
      "rf 0.9986559139784946 0.9990310077519379 0.9985875706214689\n",
      "gb 0.9959677419354839 0.9968178356118406 0.9962355012837536\n"
     ]
    }
   ],
   "source": [
    "Test_Accuracy(fitted_models, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHOOSE AND SAVE MODEL\n",
    "model = fitted_models['rf']\n",
    "with open('Models/Deadlift_rf.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=green> - ***Train Squat***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_CSV = '/Users/danielguarnizo/Desktop/ProjectCV/CSV_files/coords_SQ_C.csv'\n",
    "X_train, X_test, y_train, y_test = Create_sample_label_dataset(path_CSV)\n",
    "fitted_models = Train_Model(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr 0.9974424552429667 0.9984756097560976 0.9976851851851851\n",
      "rc 0.9974424552429667 0.9984756097560976 0.9976851851851851\n",
      "rf 0.9948849104859335 0.996969696969697 0.9953703703703703\n",
      "gb 0.9948849104859335 0.9961607949412827 0.9937169312169312\n"
     ]
    }
   ],
   "source": [
    "Test_Accuracy(fitted_models, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHOOSE AND SAVE MODEL\n",
    "model = fitted_models['rf']\n",
    "with open('Models/Squat_rf.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=green> - ***Train Bench Press***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_CSV = 'CSV_files/coords_BP_C.csv'\n",
    "X_train, X_test, y_train, y_test = Create_sample_label_dataset(path_CSV)\n",
    "fitted_models = Train_Model(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr 1.0 1.0 1.0\n",
      "rc 1.0 1.0 1.0\n",
      "rf 1.0 1.0 1.0\n",
      "gb 0.9981916817359855 0.9961538461538462 0.9975308641975309\n"
     ]
    }
   ],
   "source": [
    "Test_Accuracy(fitted_models, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHOOSE AND SAVE MODEL\n",
    "model = fitted_models['rf']\n",
    "with open('Models/Bench_rf.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=orange> - Make Predictions "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Import Dependencies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "import mediapipe as mp\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Main Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Make_Predictions(path_model, ups, downs, webcam):\n",
    "    with open(path_model, 'rb') as f:\n",
    "        model = pickle.load(f)\n",
    "\n",
    "        mp_drawing = mp.solutions.drawing_utils\n",
    "        mp_pose = mp.solutions.pose\n",
    "\n",
    "        \n",
    "        cap = cv2.VideoCapture(webcam)\n",
    "        counter = 0\n",
    "        current_stage = ''\n",
    "\n",
    "        with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "            \n",
    "            while cap.isOpened():\n",
    "                ret, image = cap.read()\n",
    "                # Mirrir image to mak easier the read on the window \n",
    "                image = cv2.flip(image, 1)\n",
    "\n",
    "                # Recolor Feed\n",
    "                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "                image.flags.writeable = False\n",
    "\n",
    "                # Make Detections\n",
    "                results = pose.process(image)\n",
    "\n",
    "                # Recolor image back to BGR for rendering\n",
    "                image.flags.writeable = True\n",
    "                image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "                mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                                        mp_drawing.DrawingSpec(color=(245, 117, 66), thickness=2, circle_radius=4),\n",
    "                                        mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2))\n",
    "                \n",
    "                try:\n",
    "                    row = np.array([[res.x, res.y, res.z, res.visibility] for res in results.pose_landmarks.landmark]).flatten().tolist()\n",
    "                    X = pd.DataFrame([row], columns = landmarks[1:])\n",
    "                    body_language_class = model.predict(X)[0]\n",
    "                    body_language_prob = model.predict_proba(X)[0]\n",
    "                    \n",
    "                    if body_language_class in downs and body_language_prob[body_language_prob.argmax()] >= 0.1:\n",
    "                        current_stage = body_language_class\n",
    "                    elif current_stage in downs and body_language_class in ups and body_language_prob[body_language_prob.argmax()] >= 0.1: # NON RIESCO A LEGGERE\n",
    "                        current_stage = body_language_class\n",
    "                        counter +=1\n",
    "                \n",
    "                    cv2.rectangle(image, (0,0), (600, 120), (245, 117, 16), -1)\n",
    "\n",
    "                    # DISPLAY CLASS\n",
    "                    cv2.putText(image, 'CLASS', (190, 24), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0,0,0), 2, cv2.LINE_AA)\n",
    "                    cv2.putText(image, body_language_class.split(' ')[0], (180,80), cv2.FONT_HERSHEY_SIMPLEX, 2, (255,255,255), 4, cv2.LINE_AA)\n",
    "\n",
    "                    # DISPLAY PROBABILITY\n",
    "                    cv2.putText(image, 'PROB', (30, 24), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0,0,0), 2, cv2.LINE_AA)\n",
    "                    cv2.putText(image, str(round(body_language_prob[np.argmax(body_language_prob)], 2)), (20,80), cv2.FONT_HERSHEY_SIMPLEX, 2, (255,255,255), 4, cv2.LINE_AA)\n",
    "\n",
    "                    # DISPLAY COUNT\n",
    "                    cv2.putText(image, 'COUNT', (480, 24), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0,0,0), 2,cv2.LINE_AA)\n",
    "                    cv2.putText(image, str(counter), (470,80), cv2.FONT_HERSHEY_SIMPLEX, 2,(255,255,255),4,cv2.LINE_AA)\n",
    "\n",
    "\n",
    "                except Exception as e:\n",
    "                    pass\n",
    "\n",
    "                cv2.imshow('Mediapipe Feed',image)\n",
    "\n",
    "                if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "                    break\n",
    "                \n",
    "        cap.release()\n",
    "        cv2.waitKey(1)\n",
    "        cv2.destroyAllWindows()\n",
    "        cv2.waitKey(1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=green> - ***Deadlift Model***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#labels = {\"up\":117, \"down\":100, \"down_low\":108, \"down_roll\":114, \"up_back\":98, \"up_roll\": 103}\n",
    "ups = [\"up\", \"up_back\", \"up_roll\"]\n",
    "downs = [\"down\", \"down_low\", \"down_roll\"]\n",
    "model_path = \"Models/Deadlift_rf.pkl\"\n",
    "webcam = 0\n",
    "Make_Predictions(model_path, ups, downs, webcam)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=green> - ***Squat Model***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# {\"up\":117, \"down\":100, \"down_deep\":108, \"down_forward\":102}\n",
    "ups = [\"up\"]\n",
    "downs = [\"down\", \"down_deep\", \"down_forward\"]\n",
    "model_path = \"Models/Squat_rf.pkl\"\n",
    "webcam = 1\n",
    "Make_Predictions(model_path, ups, downs, webcam)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=green> - ***Bench Press Model***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# {\"up\":117, \"down\":100, \"down_close\":108, \"up_close\":99, \"up_roll\":114}\n",
    "ups = [\"up\",\"up_close\", \"up_roll\"]\n",
    "downs = [\"down\", \"down_close\"]\n",
    "model_path = \"Models/Bench_rf.pkl\"\n",
    "webcam = 1\n",
    "Make_Predictions(model_path, ups, downs, webcam)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ff8880d2f4c4f0287ff51a1fdfe24c4728f28186befd2bb57d13118edd5ecb9b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
